{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.5.0)\n",
      "Requirement already satisfied: dominate>=2.4.0 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: visdom>=0.1.8.8 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.1.8.9)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: numpy in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.16.4)\n",
      "Requirement already satisfied: six in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: jsonpatch in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.32)\n",
      "Requirement already satisfied: websocket-client in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (0.59.0)\n",
      "Requirement already satisfied: scipy in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: torchfile in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: requests in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.24.0)\n",
      "Requirement already satisfied: pyzmq in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (19.0.1)\n",
      "Requirement already satisfied: tornado in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.0.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 15                            \t[default: 100]\n",
      "           n_epochs_decay: 5                             \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f1_pix2pix               \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 320\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 160, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 677, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 392, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1262, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1308, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1257, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1036, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 974, in send\n",
      "    self.connect()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 172, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f4569636eb8>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 725, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4569636eb8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 578, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4569636eb8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: /home/Yizhi/anaconda3/envs/pix2pix/bin/python -m visdom.server -p 8097 &>/dev/null &\n",
      "create web directory ./checkpoints/face_f1_pix2pix/web...\n",
      "/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.224, data: 0.640) G_GAN: 0.917 G_L1: 17.829 D_real: 0.724 D_fake: 0.662 \n",
      "(epoch: 1, iters: 200, time: 0.225, data: 0.002) G_GAN: 0.369 G_L1: 19.850 D_real: 2.067 D_fake: 0.157 \n",
      "(epoch: 1, iters: 300, time: 0.228, data: 0.002) G_GAN: 1.286 G_L1: 14.808 D_real: 0.745 D_fake: 0.083 \n",
      "End of epoch 1 / 20 \t Time Taken: 49 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 80, time: 0.481, data: 0.002) G_GAN: 0.795 G_L1: 14.225 D_real: 0.911 D_fake: 0.262 \n",
      "(epoch: 2, iters: 180, time: 0.227, data: 0.002) G_GAN: 1.916 G_L1: 16.129 D_real: 0.123 D_fake: 1.008 \n",
      "(epoch: 2, iters: 280, time: 0.230, data: 0.003) G_GAN: 1.505 G_L1: 29.713 D_real: 0.072 D_fake: 0.397 \n",
      "End of epoch 2 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 60, time: 0.229, data: 0.002) G_GAN: 2.020 G_L1: 14.043 D_real: 0.475 D_fake: 0.111 \n",
      "(epoch: 3, iters: 160, time: 0.425, data: 0.002) G_GAN: 1.090 G_L1: 14.492 D_real: 0.143 D_fake: 0.573 \n",
      "(epoch: 3, iters: 260, time: 0.228, data: 0.002) G_GAN: 1.974 G_L1: 25.786 D_real: 0.009 D_fake: 0.485 \n",
      "End of epoch 3 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 40, time: 0.228, data: 0.002) G_GAN: 1.850 G_L1: 13.090 D_real: 0.111 D_fake: 0.283 \n",
      "(epoch: 4, iters: 140, time: 0.229, data: 0.002) G_GAN: 1.290 G_L1: 13.467 D_real: 0.468 D_fake: 0.255 \n",
      "(epoch: 4, iters: 240, time: 0.430, data: 0.002) G_GAN: 1.474 G_L1: 11.549 D_real: 0.461 D_fake: 0.256 \n",
      "End of epoch 4 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 20, time: 0.230, data: 0.002) G_GAN: 1.314 G_L1: 9.985 D_real: 0.420 D_fake: 0.354 \n",
      "(epoch: 5, iters: 120, time: 0.229, data: 0.002) G_GAN: 2.019 G_L1: 14.798 D_real: 0.488 D_fake: 0.138 \n",
      "(epoch: 5, iters: 220, time: 0.229, data: 0.002) G_GAN: 1.599 G_L1: 20.565 D_real: 0.015 D_fake: 0.802 \n",
      "(epoch: 5, iters: 320, time: 0.426, data: 0.002) G_GAN: 1.872 G_L1: 14.164 D_real: 0.581 D_fake: 0.177 \n",
      "saving the model at the end of epoch 5, iters 1600\n",
      "End of epoch 5 / 20 \t Time Taken: 42 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.230, data: 0.110) G_GAN: 2.165 G_L1: 15.545 D_real: 0.082 D_fake: 0.519 \n",
      "(epoch: 6, iters: 200, time: 0.228, data: 0.002) G_GAN: 0.260 G_L1: 11.019 D_real: 1.694 D_fake: 0.338 \n",
      "(epoch: 6, iters: 300, time: 0.231, data: 0.002) G_GAN: 0.781 G_L1: 11.732 D_real: 1.962 D_fake: 0.478 \n",
      "End of epoch 6 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 80, time: 0.437, data: 0.002) G_GAN: 1.364 G_L1: 13.516 D_real: 0.755 D_fake: 0.159 \n",
      "(epoch: 7, iters: 180, time: 0.228, data: 0.002) G_GAN: 2.005 G_L1: 16.492 D_real: 0.039 D_fake: 0.304 \n",
      "(epoch: 7, iters: 280, time: 0.229, data: 0.002) G_GAN: 1.727 G_L1: 16.404 D_real: 0.046 D_fake: 0.319 \n",
      "End of epoch 7 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 60, time: 0.230, data: 0.002) G_GAN: 1.430 G_L1: 15.310 D_real: 0.030 D_fake: 0.911 \n",
      "(epoch: 8, iters: 160, time: 0.453, data: 0.002) G_GAN: 1.632 G_L1: 12.561 D_real: 0.051 D_fake: 0.646 \n",
      "(epoch: 8, iters: 260, time: 0.227, data: 0.002) G_GAN: 1.077 G_L1: 10.232 D_real: 2.259 D_fake: 0.050 \n",
      "End of epoch 8 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 40, time: 0.226, data: 0.002) G_GAN: 1.951 G_L1: 15.351 D_real: 0.083 D_fake: 0.243 \n",
      "(epoch: 9, iters: 140, time: 0.228, data: 0.002) G_GAN: 2.387 G_L1: 15.917 D_real: 0.039 D_fake: 0.377 \n",
      "(epoch: 9, iters: 240, time: 0.432, data: 0.002) G_GAN: 1.883 G_L1: 10.888 D_real: 0.299 D_fake: 0.915 \n",
      "End of epoch 9 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 20, time: 0.225, data: 0.002) G_GAN: 1.865 G_L1: 13.825 D_real: 0.078 D_fake: 0.390 \n",
      "(epoch: 10, iters: 120, time: 0.226, data: 0.002) G_GAN: 0.971 G_L1: 9.928 D_real: 1.319 D_fake: 0.207 \n",
      "(epoch: 10, iters: 220, time: 0.229, data: 0.002) G_GAN: 1.274 G_L1: 14.968 D_real: 0.014 D_fake: 1.072 \n",
      "(epoch: 10, iters: 320, time: 0.460, data: 0.002) G_GAN: 1.171 G_L1: 11.752 D_real: 0.712 D_fake: 0.155 \n",
      "saving the model at the end of epoch 10, iters 3200\n",
      "End of epoch 10 / 20 \t Time Taken: 43 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.228, data: 0.111) G_GAN: 1.501 G_L1: 12.744 D_real: 0.878 D_fake: 0.146 \n",
      "(epoch: 11, iters: 200, time: 0.231, data: 0.002) G_GAN: 1.316 G_L1: 11.069 D_real: 0.725 D_fake: 0.445 \n",
      "(epoch: 11, iters: 300, time: 0.227, data: 0.002) G_GAN: 1.577 G_L1: 8.724 D_real: 0.861 D_fake: 0.150 \n",
      "End of epoch 11 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 80, time: 0.526, data: 0.002) G_GAN: 2.164 G_L1: 12.442 D_real: 0.032 D_fake: 0.451 \n",
      "(epoch: 12, iters: 180, time: 0.224, data: 0.002) G_GAN: 2.797 G_L1: 13.463 D_real: 0.124 D_fake: 0.124 \n",
      "(epoch: 12, iters: 280, time: 0.227, data: 0.002) G_GAN: 2.817 G_L1: 15.062 D_real: 0.032 D_fake: 0.161 \n",
      "End of epoch 12 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 60, time: 0.226, data: 0.002) G_GAN: 1.542 G_L1: 10.285 D_real: 0.394 D_fake: 0.286 \n",
      "(epoch: 13, iters: 160, time: 0.425, data: 0.002) G_GAN: 1.780 G_L1: 12.495 D_real: 0.529 D_fake: 0.107 \n",
      "(epoch: 13, iters: 260, time: 0.225, data: 0.002) G_GAN: 2.882 G_L1: 12.317 D_real: 0.040 D_fake: 0.677 \n",
      "End of epoch 13 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 40, time: 0.229, data: 0.002) G_GAN: 1.722 G_L1: 11.812 D_real: 0.296 D_fake: 0.180 \n",
      "(epoch: 14, iters: 140, time: 0.227, data: 0.002) G_GAN: 1.366 G_L1: 7.686 D_real: 1.262 D_fake: 0.088 \n",
      "(epoch: 14, iters: 240, time: 0.427, data: 0.002) G_GAN: 1.920 G_L1: 12.937 D_real: 0.248 D_fake: 0.342 \n",
      "End of epoch 14 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0001667\n",
      "(epoch: 15, iters: 20, time: 0.229, data: 0.002) G_GAN: 1.416 G_L1: 8.700 D_real: 0.921 D_fake: 0.097 \n",
      "(epoch: 15, iters: 120, time: 0.225, data: 0.002) G_GAN: 2.376 G_L1: 15.537 D_real: 0.045 D_fake: 0.523 \n",
      "(epoch: 15, iters: 220, time: 0.225, data: 0.002) G_GAN: 1.955 G_L1: 11.776 D_real: 0.022 D_fake: 0.952 \n",
      "(epoch: 15, iters: 320, time: 0.481, data: 0.002) G_GAN: 1.709 G_L1: 9.276 D_real: 0.360 D_fake: 0.510 \n",
      "saving the model at the end of epoch 15, iters 4800\n",
      "End of epoch 15 / 20 \t Time Taken: 43 sec\n",
      "learning rate 0.0001667 -> 0.0001333\n",
      "(epoch: 16, iters: 100, time: 0.230, data: 0.097) G_GAN: 1.390 G_L1: 9.540 D_real: 0.686 D_fake: 0.497 \n",
      "(epoch: 16, iters: 200, time: 0.226, data: 0.002) G_GAN: 1.934 G_L1: 11.417 D_real: 0.861 D_fake: 0.066 \n",
      "saving the latest model (epoch 16, total_iters 5000)\n",
      "(epoch: 16, iters: 300, time: 0.226, data: 0.002) G_GAN: 2.417 G_L1: 13.531 D_real: 0.116 D_fake: 0.133 \n",
      "End of epoch 16 / 20 \t Time Taken: 42 sec\n",
      "learning rate 0.0001333 -> 0.0001000\n",
      "(epoch: 17, iters: 80, time: 0.473, data: 0.002) G_GAN: 1.564 G_L1: 8.449 D_real: 0.838 D_fake: 0.108 \n",
      "(epoch: 17, iters: 180, time: 0.228, data: 0.002) G_GAN: 0.674 G_L1: 8.628 D_real: 1.196 D_fake: 0.379 \n",
      "(epoch: 17, iters: 280, time: 0.229, data: 0.002) G_GAN: 2.102 G_L1: 13.379 D_real: 0.525 D_fake: 0.112 \n",
      "End of epoch 17 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0001000 -> 0.0000667\n",
      "(epoch: 18, iters: 60, time: 0.227, data: 0.002) G_GAN: 1.692 G_L1: 13.389 D_real: 0.091 D_fake: 0.318 \n",
      "(epoch: 18, iters: 160, time: 0.463, data: 0.003) G_GAN: 1.368 G_L1: 10.040 D_real: 0.925 D_fake: 0.181 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 260, time: 0.226, data: 0.002) G_GAN: 1.422 G_L1: 10.138 D_real: 0.401 D_fake: 0.314 \n",
      "End of epoch 18 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0000667 -> 0.0000333\n",
      "(epoch: 19, iters: 40, time: 0.228, data: 0.002) G_GAN: 1.278 G_L1: 6.818 D_real: 0.722 D_fake: 0.296 \n",
      "(epoch: 19, iters: 140, time: 0.231, data: 0.002) G_GAN: 1.333 G_L1: 9.030 D_real: 0.663 D_fake: 0.269 \n",
      "(epoch: 19, iters: 240, time: 0.491, data: 0.002) G_GAN: 0.921 G_L1: 9.707 D_real: 0.160 D_fake: 0.725 \n",
      "End of epoch 19 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0000333 -> 0.0000000\n",
      "(epoch: 20, iters: 20, time: 0.229, data: 0.002) G_GAN: 1.213 G_L1: 8.957 D_real: 0.706 D_fake: 0.415 \n",
      "(epoch: 20, iters: 120, time: 0.231, data: 0.002) G_GAN: 1.800 G_L1: 9.195 D_real: 0.385 D_fake: 0.211 \n",
      "(epoch: 20, iters: 220, time: 0.230, data: 0.002) G_GAN: 2.332 G_L1: 9.945 D_real: 0.375 D_fake: 0.120 \n",
      "(epoch: 20, iters: 320, time: 0.451, data: 0.002) G_GAN: 1.711 G_L1: 11.301 D_real: 0.434 D_fake: 0.230 \n",
      "saving the model at the end of epoch 20, iters 6400\n",
      "End of epoch 20 / 20 \t Time Taken: 43 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --name face_f1_pix2pix --model pix2pix --direction BtoA --n_epochs 15 --n_epochs_decay 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facades_label2photo_pretrained\tface_attempt2\tface_f1_pix2pix\r\n",
      "facades_pix2pix\t\t\tface_attempt3\thorse2zebra\r\n",
      "face_attemp1_pix2pix\t\tface_attempt5\thorse2zebra_pretrained\r\n",
      "face_attempt1\t\t\tface_attempt_b\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f1_pix2pix               \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/face_f1_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/face_f1_pix2pix/test_latest\n",
      "processing (0000)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00301.jpg']\n",
      "processing (0005)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00306.jpg']\n",
      "processing (0010)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00311.jpg']\n",
      "processing (0015)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00316.jpg']\n",
      "processing (0020)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00321.jpg']\n",
      "processing (0025)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00326.jpg']\n",
      "processing (0030)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00331.jpg']\n",
      "processing (0035)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00336.jpg']\n",
      "processing (0040)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00341.jpg']\n",
      "processing (0045)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00346.jpg']\n",
      "processing (0050)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00421.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --direction BtoA --model pix2pix --name face_f1_pix2pix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
