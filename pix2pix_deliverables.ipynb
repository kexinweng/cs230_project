{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.5.0)\n",
      "Requirement already satisfied: dominate>=2.4.0 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: visdom>=0.1.8.8 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.1.8.9)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: numpy in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.16.4)\n",
      "Requirement already satisfied: six in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: jsonpatch in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.32)\n",
      "Requirement already satisfied: websocket-client in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (0.59.0)\n",
      "Requirement already satisfied: scipy in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: torchfile in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: requests in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.24.0)\n",
      "Requirement already satisfied: pyzmq in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (19.0.1)\n",
      "Requirement already satisfied: tornado in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.0.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 15                            \t[default: 100]\n",
      "           n_epochs_decay: 5                             \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f1_pix2pix               \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 320\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 160, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 677, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 392, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1262, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1308, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1257, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1036, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 974, in send\n",
      "    self.connect()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 172, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f3994488f28>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 725, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3994488f28>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 578, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3994488f28>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: /home/Yizhi/anaconda3/envs/pix2pix/bin/python -m visdom.server -p 8097 &>/dev/null &\n",
      "create web directory ./checkpoints/face_f1_pix2pix/web...\n",
      "/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.227, data: 0.140) G_GAN: 0.845 G_L1: 22.159 D_real: 0.590 D_fake: 0.687 \n",
      "(epoch: 1, iters: 200, time: 0.228, data: 0.002) G_GAN: 1.619 G_L1: 15.345 D_real: 0.315 D_fake: 0.358 \n",
      "(epoch: 1, iters: 300, time: 0.227, data: 0.002) G_GAN: 2.371 G_L1: 14.974 D_real: 0.284 D_fake: 0.249 \n",
      "End of epoch 1 / 20 \t Time Taken: 46 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 80, time: 0.435, data: 0.002) G_GAN: 1.859 G_L1: 19.199 D_real: 0.210 D_fake: 0.508 \n",
      "(epoch: 2, iters: 180, time: 0.230, data: 0.002) G_GAN: 1.501 G_L1: 19.533 D_real: 0.133 D_fake: 0.370 \n",
      "(epoch: 2, iters: 280, time: 0.228, data: 0.002) G_GAN: 1.695 G_L1: 13.322 D_real: 2.232 D_fake: 0.072 \n",
      "End of epoch 2 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 60, time: 0.228, data: 0.002) G_GAN: 1.299 G_L1: 11.297 D_real: 0.351 D_fake: 0.401 \n",
      "(epoch: 3, iters: 160, time: 0.451, data: 0.002) G_GAN: 0.811 G_L1: 10.085 D_real: 0.828 D_fake: 0.361 \n",
      "(epoch: 3, iters: 260, time: 0.229, data: 0.002) G_GAN: 0.953 G_L1: 11.968 D_real: 1.012 D_fake: 0.687 \n",
      "End of epoch 3 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 40, time: 0.226, data: 0.002) G_GAN: 1.216 G_L1: 9.752 D_real: 1.852 D_fake: 0.137 \n",
      "(epoch: 4, iters: 140, time: 0.228, data: 0.002) G_GAN: 1.709 G_L1: 13.310 D_real: 0.134 D_fake: 0.332 \n",
      "(epoch: 4, iters: 240, time: 0.448, data: 0.002) G_GAN: 0.840 G_L1: 14.186 D_real: 0.391 D_fake: 0.651 \n",
      "End of epoch 4 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 20, time: 0.228, data: 0.002) G_GAN: 2.247 G_L1: 17.450 D_real: 0.160 D_fake: 0.393 \n",
      "(epoch: 5, iters: 120, time: 0.223, data: 0.002) G_GAN: 1.424 G_L1: 11.694 D_real: 0.840 D_fake: 0.679 \n",
      "(epoch: 5, iters: 220, time: 0.226, data: 0.002) G_GAN: 0.729 G_L1: 11.707 D_real: 0.743 D_fake: 0.331 \n",
      "(epoch: 5, iters: 320, time: 0.449, data: 0.002) G_GAN: 2.107 G_L1: 12.861 D_real: 0.101 D_fake: 0.455 \n",
      "saving the model at the end of epoch 5, iters 1600\n",
      "End of epoch 5 / 20 \t Time Taken: 44 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.227, data: 0.120) G_GAN: 1.397 G_L1: 16.047 D_real: 0.084 D_fake: 0.376 \n",
      "(epoch: 6, iters: 200, time: 0.229, data: 0.002) G_GAN: 1.755 G_L1: 9.009 D_real: 0.087 D_fake: 1.535 \n",
      "(epoch: 6, iters: 300, time: 0.226, data: 0.002) G_GAN: 0.703 G_L1: 11.054 D_real: 1.672 D_fake: 0.200 \n",
      "End of epoch 6 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 80, time: 0.473, data: 0.002) G_GAN: 1.437 G_L1: 9.046 D_real: 1.574 D_fake: 0.086 \n",
      "(epoch: 7, iters: 180, time: 0.227, data: 0.002) G_GAN: 1.699 G_L1: 13.576 D_real: 0.327 D_fake: 0.206 \n",
      "(epoch: 7, iters: 280, time: 0.226, data: 0.002) G_GAN: 0.479 G_L1: 11.056 D_real: 1.246 D_fake: 0.244 \n",
      "End of epoch 7 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 60, time: 0.226, data: 0.002) G_GAN: 1.118 G_L1: 10.009 D_real: 1.383 D_fake: 0.158 \n",
      "(epoch: 8, iters: 160, time: 0.457, data: 0.002) G_GAN: 0.615 G_L1: 11.038 D_real: 1.872 D_fake: 0.165 \n",
      "(epoch: 8, iters: 260, time: 0.227, data: 0.002) G_GAN: 2.028 G_L1: 11.242 D_real: 0.067 D_fake: 0.489 \n",
      "End of epoch 8 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 40, time: 0.225, data: 0.002) G_GAN: 2.072 G_L1: 13.252 D_real: 0.102 D_fake: 1.143 \n",
      "(epoch: 9, iters: 140, time: 0.228, data: 0.002) G_GAN: 1.636 G_L1: 13.181 D_real: 0.316 D_fake: 0.354 \n",
      "(epoch: 9, iters: 240, time: 0.422, data: 0.002) G_GAN: 2.148 G_L1: 14.660 D_real: 0.051 D_fake: 0.370 \n",
      "End of epoch 9 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 20, time: 0.228, data: 0.002) G_GAN: 2.061 G_L1: 18.930 D_real: 0.009 D_fake: 0.527 \n",
      "(epoch: 10, iters: 120, time: 0.228, data: 0.002) G_GAN: 2.201 G_L1: 12.588 D_real: 0.254 D_fake: 0.276 \n",
      "(epoch: 10, iters: 220, time: 0.224, data: 0.002) G_GAN: 2.330 G_L1: 13.492 D_real: 0.211 D_fake: 0.136 \n",
      "(epoch: 10, iters: 320, time: 0.454, data: 0.002) G_GAN: 1.068 G_L1: 9.162 D_real: 0.543 D_fake: 0.415 \n",
      "saving the model at the end of epoch 10, iters 3200\n",
      "End of epoch 10 / 20 \t Time Taken: 44 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.225, data: 0.093) G_GAN: 1.795 G_L1: 14.188 D_real: 0.173 D_fake: 0.253 \n",
      "(epoch: 11, iters: 200, time: 0.227, data: 0.002) G_GAN: 2.404 G_L1: 11.484 D_real: 0.098 D_fake: 0.274 \n",
      "(epoch: 11, iters: 300, time: 0.223, data: 0.002) G_GAN: 2.297 G_L1: 12.664 D_real: 0.347 D_fake: 0.165 \n",
      "End of epoch 11 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 80, time: 0.483, data: 0.002) G_GAN: 0.637 G_L1: 8.835 D_real: 1.007 D_fake: 0.500 \n",
      "(epoch: 12, iters: 180, time: 0.224, data: 0.002) G_GAN: 1.745 G_L1: 12.149 D_real: 0.265 D_fake: 0.232 \n",
      "(epoch: 12, iters: 280, time: 0.228, data: 0.002) G_GAN: 1.431 G_L1: 10.357 D_real: 0.753 D_fake: 0.724 \n",
      "End of epoch 12 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 60, time: 0.225, data: 0.002) G_GAN: 1.689 G_L1: 11.998 D_real: 0.835 D_fake: 0.280 \n",
      "(epoch: 13, iters: 160, time: 0.422, data: 0.002) G_GAN: 1.958 G_L1: 14.121 D_real: 0.125 D_fake: 0.759 \n",
      "(epoch: 13, iters: 260, time: 0.225, data: 0.002) G_GAN: 1.217 G_L1: 11.810 D_real: 0.714 D_fake: 0.147 \n",
      "End of epoch 13 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 40, time: 0.228, data: 0.002) G_GAN: 1.327 G_L1: 10.957 D_real: 0.591 D_fake: 0.165 \n",
      "(epoch: 14, iters: 140, time: 0.227, data: 0.002) G_GAN: 2.346 G_L1: 14.042 D_real: 0.019 D_fake: 0.386 \n",
      "(epoch: 14, iters: 240, time: 0.472, data: 0.002) G_GAN: 0.895 G_L1: 9.312 D_real: 0.569 D_fake: 0.491 \n",
      "End of epoch 14 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0001667\n",
      "(epoch: 15, iters: 20, time: 0.223, data: 0.002) G_GAN: 2.347 G_L1: 11.718 D_real: 0.276 D_fake: 0.147 \n",
      "(epoch: 15, iters: 120, time: 0.226, data: 0.002) G_GAN: 1.604 G_L1: 11.391 D_real: 0.506 D_fake: 0.198 \n",
      "(epoch: 15, iters: 220, time: 0.225, data: 0.002) G_GAN: 1.657 G_L1: 9.142 D_real: 0.260 D_fake: 0.566 \n",
      "(epoch: 15, iters: 320, time: 0.460, data: 0.002) G_GAN: 3.052 G_L1: 16.344 D_real: 0.014 D_fake: 0.198 \n",
      "saving the model at the end of epoch 15, iters 4800\n",
      "End of epoch 15 / 20 \t Time Taken: 44 sec\n",
      "learning rate 0.0001667 -> 0.0001333\n",
      "(epoch: 16, iters: 100, time: 0.228, data: 0.107) G_GAN: 1.489 G_L1: 10.927 D_real: 0.139 D_fake: 0.468 \n",
      "(epoch: 16, iters: 200, time: 0.228, data: 0.002) G_GAN: 3.336 G_L1: 14.767 D_real: 0.056 D_fake: 0.064 \n",
      "saving the latest model (epoch 16, total_iters 5000)\n",
      "(epoch: 16, iters: 300, time: 0.225, data: 0.002) G_GAN: 1.465 G_L1: 11.414 D_real: 0.264 D_fake: 0.423 \n",
      "End of epoch 16 / 20 \t Time Taken: 42 sec\n",
      "learning rate 0.0001333 -> 0.0001000\n",
      "(epoch: 17, iters: 80, time: 0.464, data: 0.002) G_GAN: 1.780 G_L1: 13.616 D_real: 0.236 D_fake: 0.172 \n",
      "(epoch: 17, iters: 180, time: 0.226, data: 0.003) G_GAN: 3.012 G_L1: 14.465 D_real: 0.017 D_fake: 0.079 \n",
      "(epoch: 17, iters: 280, time: 0.226, data: 0.002) G_GAN: 2.226 G_L1: 13.328 D_real: 0.035 D_fake: 0.246 \n",
      "End of epoch 17 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0001000 -> 0.0000667\n",
      "(epoch: 18, iters: 60, time: 0.228, data: 0.002) G_GAN: 1.905 G_L1: 12.324 D_real: 1.286 D_fake: 0.088 \n",
      "(epoch: 18, iters: 160, time: 0.467, data: 0.002) G_GAN: 1.353 G_L1: 10.985 D_real: 0.293 D_fake: 0.624 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 260, time: 0.225, data: 0.002) G_GAN: 1.808 G_L1: 10.999 D_real: 0.624 D_fake: 0.096 \n",
      "End of epoch 18 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0000667 -> 0.0000333\n",
      "(epoch: 19, iters: 40, time: 0.227, data: 0.002) G_GAN: 1.630 G_L1: 10.076 D_real: 0.665 D_fake: 0.219 \n",
      "(epoch: 19, iters: 140, time: 0.227, data: 0.002) G_GAN: 2.244 G_L1: 14.088 D_real: 0.048 D_fake: 0.184 \n",
      "(epoch: 19, iters: 240, time: 0.462, data: 0.002) G_GAN: 1.135 G_L1: 10.536 D_real: 0.237 D_fake: 0.539 \n",
      "End of epoch 19 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0000333 -> 0.0000000\n",
      "(epoch: 20, iters: 20, time: 0.222, data: 0.002) G_GAN: 1.010 G_L1: 11.273 D_real: 0.373 D_fake: 0.532 \n",
      "(epoch: 20, iters: 120, time: 0.228, data: 0.003) G_GAN: 0.682 G_L1: 10.288 D_real: 0.198 D_fake: 0.799 \n",
      "(epoch: 20, iters: 220, time: 0.225, data: 0.002) G_GAN: 1.113 G_L1: 8.833 D_real: 0.435 D_fake: 0.442 \n",
      "(epoch: 20, iters: 320, time: 0.491, data: 0.002) G_GAN: 2.012 G_L1: 10.082 D_real: 1.105 D_fake: 0.169 \n",
      "saving the model at the end of epoch 20, iters 6400\n",
      "End of epoch 20 / 20 \t Time Taken: 44 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --name face_f1_pix2pix --model pix2pix --direction BtoA --n_epochs 15 --n_epochs_decay 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facades_label2photo_pretrained\tface_attempt2\tface_f1_pix2pix\r\n",
      "facades_pix2pix\t\t\tface_attempt3\thorse2zebra\r\n",
      "face_attemp1_pix2pix\t\tface_attempt5\thorse2zebra_pretrained\r\n",
      "face_attempt1\t\t\tface_attempt_b\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f1_pix2pix               \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/face_f1_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/face_f1_pix2pix/test_latest\n",
      "processing (0000)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00301.jpg']\n",
      "processing (0005)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00306.jpg']\n",
      "processing (0010)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00311.jpg']\n",
      "processing (0015)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00316.jpg']\n",
      "processing (0020)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00321.jpg']\n",
      "processing (0025)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00326.jpg']\n",
      "processing (0030)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00331.jpg']\n",
      "processing (0035)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00336.jpg']\n",
      "processing (0040)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00341.jpg']\n",
      "processing (0045)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00346.jpg']\n",
      "processing (0050)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00421.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --direction BtoA --model pix2pix --name face_f1_pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 15                            \t[default: 100]\n",
      "           n_epochs_decay: 5                             \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f2_unet128_pix2pix       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_128                      \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 320\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 41.829 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 160, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 677, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 392, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1262, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1308, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1257, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1036, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 974, in send\n",
      "    self.connect()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 172, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc85a787ba8>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 725, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc85a787ba8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 578, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc85a787ba8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: /home/Yizhi/anaconda3/envs/pix2pix/bin/python -m visdom.server -p 8097 &>/dev/null &\n",
      "create web directory ./checkpoints/face_f2_unet128_pix2pix/web...\n",
      "/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.196, data: 0.150) G_GAN: 0.922 G_L1: 16.793 D_real: 0.579 D_fake: 0.571 \n",
      "(epoch: 1, iters: 200, time: 0.193, data: 0.002) G_GAN: 1.722 G_L1: 15.545 D_real: 0.638 D_fake: 0.241 \n",
      "(epoch: 1, iters: 300, time: 0.198, data: 0.002) G_GAN: 1.593 G_L1: 13.348 D_real: 0.369 D_fake: 0.605 \n",
      "End of epoch 1 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 80, time: 0.381, data: 0.002) G_GAN: 2.497 G_L1: 18.328 D_real: 0.107 D_fake: 0.536 \n",
      "(epoch: 2, iters: 180, time: 0.195, data: 0.002) G_GAN: 0.886 G_L1: 13.981 D_real: 1.286 D_fake: 0.264 \n",
      "(epoch: 2, iters: 280, time: 0.201, data: 0.002) G_GAN: 1.687 G_L1: 16.447 D_real: 1.150 D_fake: 0.109 \n",
      "End of epoch 2 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 60, time: 0.198, data: 0.002) G_GAN: 2.492 G_L1: 15.958 D_real: 0.012 D_fake: 0.872 \n",
      "(epoch: 3, iters: 160, time: 0.347, data: 0.002) G_GAN: 1.766 G_L1: 23.959 D_real: 0.043 D_fake: 0.247 \n",
      "(epoch: 3, iters: 260, time: 0.197, data: 0.002) G_GAN: 1.193 G_L1: 14.539 D_real: 0.323 D_fake: 0.297 \n",
      "End of epoch 3 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 40, time: 0.202, data: 0.002) G_GAN: 1.921 G_L1: 16.087 D_real: 0.373 D_fake: 0.192 \n",
      "(epoch: 4, iters: 140, time: 0.194, data: 0.002) G_GAN: 1.879 G_L1: 21.597 D_real: 0.002 D_fake: 1.664 \n",
      "(epoch: 4, iters: 240, time: 0.385, data: 0.002) G_GAN: 2.016 G_L1: 15.205 D_real: 0.339 D_fake: 0.145 \n",
      "End of epoch 4 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 20, time: 0.199, data: 0.002) G_GAN: 1.566 G_L1: 13.329 D_real: 1.156 D_fake: 0.102 \n",
      "(epoch: 5, iters: 120, time: 0.196, data: 0.002) G_GAN: 1.396 G_L1: 10.840 D_real: 0.677 D_fake: 0.165 \n",
      "(epoch: 5, iters: 220, time: 0.203, data: 0.002) G_GAN: 1.254 G_L1: 15.371 D_real: 0.363 D_fake: 0.331 \n",
      "(epoch: 5, iters: 320, time: 0.398, data: 0.002) G_GAN: 1.252 G_L1: 14.183 D_real: 0.876 D_fake: 0.512 \n",
      "saving the model at the end of epoch 5, iters 1600\n",
      "End of epoch 5 / 20 \t Time Taken: 36 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.198, data: 0.099) G_GAN: 1.369 G_L1: 11.861 D_real: 0.195 D_fake: 0.616 \n",
      "(epoch: 6, iters: 200, time: 0.195, data: 0.002) G_GAN: 0.555 G_L1: 8.815 D_real: 1.555 D_fake: 0.272 \n",
      "(epoch: 6, iters: 300, time: 0.201, data: 0.002) G_GAN: 1.472 G_L1: 16.135 D_real: 0.042 D_fake: 0.307 \n",
      "End of epoch 6 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 80, time: 0.428, data: 0.002) G_GAN: 1.435 G_L1: 10.163 D_real: 0.268 D_fake: 0.644 \n",
      "(epoch: 7, iters: 180, time: 0.201, data: 0.002) G_GAN: 1.333 G_L1: 10.630 D_real: 1.326 D_fake: 0.084 \n",
      "(epoch: 7, iters: 280, time: 0.200, data: 0.002) G_GAN: 2.043 G_L1: 14.232 D_real: 0.306 D_fake: 0.118 \n",
      "End of epoch 7 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 60, time: 0.198, data: 0.002) G_GAN: 2.713 G_L1: 19.096 D_real: 0.027 D_fake: 0.538 \n",
      "(epoch: 8, iters: 160, time: 0.428, data: 0.002) G_GAN: 1.534 G_L1: 11.458 D_real: 0.277 D_fake: 0.303 \n",
      "(epoch: 8, iters: 260, time: 0.196, data: 0.002) G_GAN: 0.603 G_L1: 9.036 D_real: 1.557 D_fake: 0.221 \n",
      "End of epoch 8 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 40, time: 0.201, data: 0.002) G_GAN: 1.961 G_L1: 16.272 D_real: 0.040 D_fake: 0.197 \n",
      "(epoch: 9, iters: 140, time: 0.196, data: 0.002) G_GAN: 1.183 G_L1: 10.131 D_real: 1.812 D_fake: 0.104 \n",
      "(epoch: 9, iters: 240, time: 0.398, data: 0.002) G_GAN: 2.250 G_L1: 15.501 D_real: 0.246 D_fake: 0.237 \n",
      "End of epoch 9 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 20, time: 0.193, data: 0.002) G_GAN: 1.881 G_L1: 11.131 D_real: 0.239 D_fake: 0.279 \n",
      "(epoch: 10, iters: 120, time: 0.198, data: 0.002) G_GAN: 2.534 G_L1: 15.108 D_real: 0.370 D_fake: 0.106 \n",
      "(epoch: 10, iters: 220, time: 0.199, data: 0.002) G_GAN: 0.296 G_L1: 10.403 D_real: 1.388 D_fake: 0.302 \n",
      "(epoch: 10, iters: 320, time: 0.451, data: 0.002) G_GAN: 1.097 G_L1: 8.520 D_real: 0.611 D_fake: 1.326 \n",
      "saving the model at the end of epoch 10, iters 3200\n",
      "End of epoch 10 / 20 \t Time Taken: 37 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.201, data: 0.093) G_GAN: 2.060 G_L1: 19.287 D_real: 0.018 D_fake: 0.590 \n",
      "(epoch: 11, iters: 200, time: 0.196, data: 0.002) G_GAN: 0.803 G_L1: 10.635 D_real: 1.974 D_fake: 0.421 \n",
      "(epoch: 11, iters: 300, time: 0.202, data: 0.002) G_GAN: 1.069 G_L1: 9.953 D_real: 0.460 D_fake: 1.066 \n",
      "End of epoch 11 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 80, time: 0.402, data: 0.002) G_GAN: 1.772 G_L1: 10.263 D_real: 0.396 D_fake: 0.145 \n",
      "(epoch: 12, iters: 180, time: 0.199, data: 0.002) G_GAN: 1.421 G_L1: 12.777 D_real: 0.403 D_fake: 0.793 \n",
      "(epoch: 12, iters: 280, time: 0.193, data: 0.002) G_GAN: 2.500 G_L1: 15.279 D_real: 0.065 D_fake: 0.218 \n",
      "End of epoch 12 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 60, time: 0.194, data: 0.002) G_GAN: 3.692 G_L1: 15.686 D_real: 0.211 D_fake: 0.043 \n",
      "(epoch: 13, iters: 160, time: 0.407, data: 0.002) G_GAN: 1.938 G_L1: 10.434 D_real: 0.511 D_fake: 1.052 \n",
      "(epoch: 13, iters: 260, time: 0.194, data: 0.002) G_GAN: 1.404 G_L1: 8.946 D_real: 0.451 D_fake: 0.498 \n",
      "End of epoch 13 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 40, time: 0.195, data: 0.002) G_GAN: 0.969 G_L1: 7.983 D_real: 1.061 D_fake: 0.416 \n",
      "(epoch: 14, iters: 140, time: 0.200, data: 0.002) G_GAN: 1.770 G_L1: 9.540 D_real: 0.694 D_fake: 0.100 \n",
      "(epoch: 14, iters: 240, time: 0.444, data: 0.002) G_GAN: 1.680 G_L1: 10.607 D_real: 0.697 D_fake: 0.114 \n",
      "End of epoch 14 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0002000 -> 0.0001667\n",
      "(epoch: 15, iters: 20, time: 0.197, data: 0.002) G_GAN: 1.177 G_L1: 10.833 D_real: 0.404 D_fake: 0.271 \n",
      "(epoch: 15, iters: 120, time: 0.180, data: 0.002) G_GAN: 1.627 G_L1: 11.622 D_real: 0.489 D_fake: 0.191 \n",
      "(epoch: 15, iters: 220, time: 0.198, data: 0.002) G_GAN: 2.011 G_L1: 15.101 D_real: 0.012 D_fake: 0.893 \n",
      "(epoch: 15, iters: 320, time: 0.431, data: 0.002) G_GAN: 1.088 G_L1: 9.825 D_real: 0.475 D_fake: 0.492 \n",
      "saving the model at the end of epoch 15, iters 4800\n",
      "End of epoch 15 / 20 \t Time Taken: 37 sec\n",
      "learning rate 0.0001667 -> 0.0001333\n",
      "(epoch: 16, iters: 100, time: 0.195, data: 0.126) G_GAN: 2.290 G_L1: 13.156 D_real: 0.463 D_fake: 0.116 \n",
      "(epoch: 16, iters: 200, time: 0.199, data: 0.002) G_GAN: 2.101 G_L1: 14.730 D_real: 0.023 D_fake: 0.723 \n",
      "saving the latest model (epoch 16, total_iters 5000)\n",
      "(epoch: 16, iters: 300, time: 0.196, data: 0.002) G_GAN: 1.449 G_L1: 14.062 D_real: 0.066 D_fake: 0.428 \n",
      "End of epoch 16 / 20 \t Time Taken: 37 sec\n",
      "learning rate 0.0001333 -> 0.0001000\n",
      "(epoch: 17, iters: 80, time: 0.457, data: 0.002) G_GAN: 1.827 G_L1: 10.097 D_real: 0.409 D_fake: 0.189 \n",
      "(epoch: 17, iters: 180, time: 0.198, data: 0.002) G_GAN: 1.891 G_L1: 15.718 D_real: 0.002 D_fake: 0.795 \n",
      "(epoch: 17, iters: 280, time: 0.196, data: 0.002) G_GAN: 2.252 G_L1: 14.652 D_real: 0.073 D_fake: 0.168 \n",
      "End of epoch 17 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0001000 -> 0.0000667\n",
      "(epoch: 18, iters: 60, time: 0.197, data: 0.002) G_GAN: 1.559 G_L1: 12.950 D_real: 0.007 D_fake: 0.582 \n",
      "(epoch: 18, iters: 160, time: 0.450, data: 0.002) G_GAN: 1.655 G_L1: 8.969 D_real: 0.352 D_fake: 0.771 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 260, time: 0.196, data: 0.002) G_GAN: 1.926 G_L1: 13.942 D_real: 0.073 D_fake: 0.337 \n",
      "End of epoch 18 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0000667 -> 0.0000333\n",
      "(epoch: 19, iters: 40, time: 0.202, data: 0.002) G_GAN: 1.638 G_L1: 12.001 D_real: 0.048 D_fake: 0.389 \n",
      "(epoch: 19, iters: 140, time: 0.197, data: 0.002) G_GAN: 2.702 G_L1: 13.042 D_real: 0.112 D_fake: 0.095 \n",
      "(epoch: 19, iters: 240, time: 0.433, data: 0.002) G_GAN: 2.046 G_L1: 12.202 D_real: 0.072 D_fake: 0.173 \n",
      "End of epoch 19 / 20 \t Time Taken: 35 sec\n",
      "learning rate 0.0000333 -> 0.0000000\n",
      "(epoch: 20, iters: 20, time: 0.201, data: 0.002) G_GAN: 1.698 G_L1: 11.964 D_real: 0.204 D_fake: 0.234 \n",
      "(epoch: 20, iters: 120, time: 0.193, data: 0.002) G_GAN: 2.901 G_L1: 9.246 D_real: 1.471 D_fake: 0.066 \n",
      "(epoch: 20, iters: 220, time: 0.202, data: 0.002) G_GAN: 1.611 G_L1: 9.067 D_real: 0.757 D_fake: 0.251 \n",
      "(epoch: 20, iters: 320, time: 0.430, data: 0.002) G_GAN: 1.729 G_L1: 13.277 D_real: 0.096 D_fake: 0.244 \n",
      "saving the model at the end of epoch 20, iters 6400\n",
      "End of epoch 20 / 20 \t Time Taken: 37 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --name face_f2_unet128_pix2pix --model pix2pix --netG 'unet_128' --direction BtoA --n_epochs 15 --n_epochs_decay 5\n",
    "# unet128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 15                            \t[default: 100]\n",
      "           n_epochs_decay: 5                             \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f2_unet256_pix2pix       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 320\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 160, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 677, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 392, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1262, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1308, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1257, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1036, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 974, in send\n",
      "    self.connect()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 172, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f079c874f60>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 725, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f079c874f60>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 578, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f079c874f60>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: /home/Yizhi/anaconda3/envs/pix2pix/bin/python -m visdom.server -p 8097 &>/dev/null &\n",
      "create web directory ./checkpoints/face_f2_unet256_pix2pix/web...\n",
      "/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.225, data: 0.204) G_GAN: 0.828 G_L1: 23.497 D_real: 0.706 D_fake: 0.724 \n",
      "(epoch: 1, iters: 200, time: 0.225, data: 0.002) G_GAN: 1.493 G_L1: 19.219 D_real: 0.488 D_fake: 0.464 \n",
      "(epoch: 1, iters: 300, time: 0.224, data: 0.002) G_GAN: 2.565 G_L1: 21.241 D_real: 0.090 D_fake: 0.174 \n",
      "End of epoch 1 / 20 \t Time Taken: 46 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 80, time: 0.430, data: 0.002) G_GAN: 1.721 G_L1: 14.503 D_real: 0.279 D_fake: 0.186 \n",
      "(epoch: 2, iters: 180, time: 0.223, data: 0.002) G_GAN: 1.622 G_L1: 13.853 D_real: 0.506 D_fake: 0.168 \n",
      "(epoch: 2, iters: 280, time: 0.229, data: 0.002) G_GAN: 1.055 G_L1: 10.906 D_real: 1.466 D_fake: 0.196 \n",
      "End of epoch 2 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 60, time: 0.230, data: 0.002) G_GAN: 2.002 G_L1: 17.379 D_real: 0.084 D_fake: 0.370 \n",
      "(epoch: 3, iters: 160, time: 0.383, data: 0.002) G_GAN: 1.661 G_L1: 19.236 D_real: 0.412 D_fake: 0.293 \n",
      "(epoch: 3, iters: 260, time: 0.226, data: 0.002) G_GAN: 2.017 G_L1: 23.917 D_real: 0.041 D_fake: 0.258 \n",
      "End of epoch 3 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 40, time: 0.224, data: 0.002) G_GAN: 1.299 G_L1: 22.294 D_real: 0.007 D_fake: 0.928 \n",
      "(epoch: 4, iters: 140, time: 0.228, data: 0.002) G_GAN: 1.615 G_L1: 14.339 D_real: 0.201 D_fake: 0.401 \n",
      "(epoch: 4, iters: 240, time: 0.449, data: 0.002) G_GAN: 0.798 G_L1: 10.845 D_real: 1.197 D_fake: 0.298 \n",
      "End of epoch 4 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 20, time: 0.227, data: 0.002) G_GAN: 1.098 G_L1: 12.868 D_real: 0.355 D_fake: 0.357 \n",
      "(epoch: 5, iters: 120, time: 0.225, data: 0.002) G_GAN: 0.983 G_L1: 11.290 D_real: 0.813 D_fake: 0.276 \n",
      "(epoch: 5, iters: 220, time: 0.228, data: 0.002) G_GAN: 1.377 G_L1: 10.121 D_real: 0.850 D_fake: 0.223 \n",
      "(epoch: 5, iters: 320, time: 0.428, data: 0.002) G_GAN: 1.345 G_L1: 14.377 D_real: 0.348 D_fake: 0.200 \n",
      "saving the model at the end of epoch 5, iters 1600\n",
      "End of epoch 5 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.226, data: 0.113) G_GAN: 0.396 G_L1: 10.543 D_real: 1.507 D_fake: 0.273 \n",
      "(epoch: 6, iters: 200, time: 0.226, data: 0.002) G_GAN: 1.018 G_L1: 12.301 D_real: 0.565 D_fake: 0.310 \n",
      "(epoch: 6, iters: 300, time: 0.230, data: 0.002) G_GAN: 0.846 G_L1: 10.780 D_real: 0.687 D_fake: 0.248 \n",
      "End of epoch 6 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 80, time: 0.449, data: 0.002) G_GAN: 1.096 G_L1: 13.288 D_real: 1.193 D_fake: 0.280 \n",
      "(epoch: 7, iters: 180, time: 0.229, data: 0.002) G_GAN: 2.423 G_L1: 20.142 D_real: 0.023 D_fake: 0.188 \n",
      "(epoch: 7, iters: 280, time: 0.227, data: 0.002) G_GAN: 1.671 G_L1: 11.831 D_real: 0.738 D_fake: 0.105 \n",
      "End of epoch 7 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 60, time: 0.226, data: 0.002) G_GAN: 0.898 G_L1: 12.850 D_real: 1.278 D_fake: 0.286 \n",
      "(epoch: 8, iters: 160, time: 0.536, data: 0.002) G_GAN: 0.983 G_L1: 9.558 D_real: 0.697 D_fake: 0.729 \n",
      "(epoch: 8, iters: 260, time: 0.226, data: 0.003) G_GAN: 0.535 G_L1: 13.121 D_real: 1.193 D_fake: 0.234 \n",
      "End of epoch 8 / 20 \t Time Taken: 41 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 40, time: 0.227, data: 0.002) G_GAN: 1.458 G_L1: 15.426 D_real: 0.009 D_fake: 0.529 \n",
      "(epoch: 9, iters: 140, time: 0.228, data: 0.002) G_GAN: 2.605 G_L1: 13.350 D_real: 0.134 D_fake: 1.373 \n",
      "(epoch: 9, iters: 240, time: 0.434, data: 0.002) G_GAN: 2.243 G_L1: 12.957 D_real: 0.226 D_fake: 0.155 \n",
      "End of epoch 9 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 20, time: 0.225, data: 0.003) G_GAN: 2.035 G_L1: 14.136 D_real: 0.662 D_fake: 0.305 \n",
      "(epoch: 10, iters: 120, time: 0.226, data: 0.002) G_GAN: 1.977 G_L1: 13.941 D_real: 0.213 D_fake: 0.181 \n",
      "(epoch: 10, iters: 220, time: 0.227, data: 0.002) G_GAN: 1.736 G_L1: 18.501 D_real: 0.006 D_fake: 1.359 \n",
      "(epoch: 10, iters: 320, time: 0.459, data: 0.002) G_GAN: 1.308 G_L1: 11.154 D_real: 0.643 D_fake: 0.199 \n",
      "saving the model at the end of epoch 10, iters 3200\n",
      "End of epoch 10 / 20 \t Time Taken: 43 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.221, data: 0.106) G_GAN: 1.662 G_L1: 11.570 D_real: 0.448 D_fake: 0.333 \n",
      "(epoch: 11, iters: 200, time: 0.226, data: 0.002) G_GAN: 2.373 G_L1: 10.803 D_real: 0.075 D_fake: 1.135 \n",
      "(epoch: 11, iters: 300, time: 0.225, data: 0.002) G_GAN: 1.814 G_L1: 12.385 D_real: 0.102 D_fake: 0.394 \n",
      "End of epoch 11 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 80, time: 0.443, data: 0.002) G_GAN: 1.723 G_L1: 12.940 D_real: 0.700 D_fake: 0.117 \n",
      "(epoch: 12, iters: 180, time: 0.224, data: 0.002) G_GAN: 2.029 G_L1: 9.445 D_real: 0.178 D_fake: 0.513 \n",
      "(epoch: 12, iters: 280, time: 0.227, data: 0.002) G_GAN: 2.163 G_L1: 11.100 D_real: 0.338 D_fake: 0.467 \n",
      "End of epoch 12 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 60, time: 0.227, data: 0.002) G_GAN: 1.694 G_L1: 13.425 D_real: 0.008 D_fake: 0.956 \n",
      "(epoch: 13, iters: 160, time: 0.448, data: 0.002) G_GAN: 2.050 G_L1: 12.391 D_real: 0.151 D_fake: 0.204 \n",
      "(epoch: 13, iters: 260, time: 0.227, data: 0.002) G_GAN: 1.667 G_L1: 23.588 D_real: 0.561 D_fake: 0.147 \n",
      "End of epoch 13 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 40, time: 0.227, data: 0.002) G_GAN: 1.224 G_L1: 8.869 D_real: 0.322 D_fake: 0.379 \n",
      "(epoch: 14, iters: 140, time: 0.228, data: 0.002) G_GAN: 2.197 G_L1: 17.726 D_real: 0.002 D_fake: 0.340 \n",
      "(epoch: 14, iters: 240, time: 0.443, data: 0.002) G_GAN: 2.580 G_L1: 14.373 D_real: 0.027 D_fake: 0.958 \n",
      "End of epoch 14 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0002000 -> 0.0001667\n",
      "(epoch: 15, iters: 20, time: 0.229, data: 0.002) G_GAN: 1.822 G_L1: 18.360 D_real: 0.002 D_fake: 0.728 \n",
      "(epoch: 15, iters: 120, time: 0.223, data: 0.002) G_GAN: 1.786 G_L1: 11.781 D_real: 0.244 D_fake: 0.153 \n",
      "(epoch: 15, iters: 220, time: 0.221, data: 0.002) G_GAN: 1.959 G_L1: 10.022 D_real: 0.287 D_fake: 0.117 \n",
      "(epoch: 15, iters: 320, time: 0.435, data: 0.002) G_GAN: 2.539 G_L1: 12.781 D_real: 0.116 D_fake: 0.693 \n",
      "saving the model at the end of epoch 15, iters 4800\n",
      "End of epoch 15 / 20 \t Time Taken: 43 sec\n",
      "learning rate 0.0001667 -> 0.0001333\n",
      "(epoch: 16, iters: 100, time: 0.225, data: 0.098) G_GAN: 2.424 G_L1: 12.980 D_real: 0.024 D_fake: 0.203 \n",
      "(epoch: 16, iters: 200, time: 0.226, data: 0.002) G_GAN: 2.579 G_L1: 12.414 D_real: 0.050 D_fake: 0.151 \n",
      "saving the latest model (epoch 16, total_iters 5000)\n",
      "(epoch: 16, iters: 300, time: 0.227, data: 0.002) G_GAN: 2.425 G_L1: 14.346 D_real: 0.037 D_fake: 0.191 \n",
      "End of epoch 16 / 20 \t Time Taken: 42 sec\n",
      "learning rate 0.0001333 -> 0.0001000\n",
      "(epoch: 17, iters: 80, time: 0.450, data: 0.002) G_GAN: 1.980 G_L1: 12.638 D_real: 0.084 D_fake: 0.302 \n",
      "(epoch: 17, iters: 180, time: 0.228, data: 0.002) G_GAN: 2.386 G_L1: 15.875 D_real: 0.015 D_fake: 1.380 \n",
      "(epoch: 17, iters: 280, time: 0.227, data: 0.002) G_GAN: 1.522 G_L1: 8.804 D_real: 0.278 D_fake: 0.532 \n",
      "End of epoch 17 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0001000 -> 0.0000667\n",
      "(epoch: 18, iters: 60, time: 0.229, data: 0.002) G_GAN: 2.450 G_L1: 9.166 D_real: 0.673 D_fake: 0.049 \n",
      "(epoch: 18, iters: 160, time: 0.451, data: 0.002) G_GAN: 1.422 G_L1: 14.580 D_real: 0.035 D_fake: 0.469 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 260, time: 0.227, data: 0.002) G_GAN: 1.670 G_L1: 13.652 D_real: 0.263 D_fake: 0.245 \n",
      "End of epoch 18 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0000667 -> 0.0000333\n",
      "(epoch: 19, iters: 40, time: 0.223, data: 0.002) G_GAN: 1.604 G_L1: 7.244 D_real: 1.083 D_fake: 0.224 \n",
      "(epoch: 19, iters: 140, time: 0.225, data: 0.002) G_GAN: 1.520 G_L1: 12.336 D_real: 0.282 D_fake: 0.278 \n",
      "(epoch: 19, iters: 240, time: 0.465, data: 0.002) G_GAN: 1.822 G_L1: 11.294 D_real: 0.033 D_fake: 0.260 \n",
      "End of epoch 19 / 20 \t Time Taken: 40 sec\n",
      "learning rate 0.0000333 -> 0.0000000\n",
      "(epoch: 20, iters: 20, time: 0.225, data: 0.002) G_GAN: 2.728 G_L1: 9.899 D_real: 0.787 D_fake: 0.083 \n",
      "(epoch: 20, iters: 120, time: 0.229, data: 0.002) G_GAN: 2.319 G_L1: 9.715 D_real: 0.595 D_fake: 0.119 \n",
      "(epoch: 20, iters: 220, time: 0.227, data: 0.002) G_GAN: 1.886 G_L1: 9.850 D_real: 0.509 D_fake: 0.191 \n",
      "(epoch: 20, iters: 320, time: 0.514, data: 0.002) G_GAN: 2.282 G_L1: 8.229 D_real: 0.986 D_fake: 0.123 \n",
      "saving the model at the end of epoch 20, iters 6400\n",
      "End of epoch 20 / 20 \t Time Taken: 43 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --name face_f2_unet256_pix2pix --model pix2pix --netG 'unet_256' --direction BtoA --n_epochs 15 --n_epochs_decay 5\n",
    "# unet256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 15                            \t[default: 100]\n",
      "           n_epochs_decay: 5                             \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f2_res6_pix2pix          \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_6blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 320\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 7.841 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 160, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 677, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 392, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1262, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1308, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1257, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 1036, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/http/client.py\", line 974, in send\n",
      "    self.connect()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connection.py\", line 172, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc737b1a710>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 725, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/urllib3/util/retry.py\", line 439, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc737b1a710>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 578, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc737b1a710>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: /home/Yizhi/anaconda3/envs/pix2pix/bin/python -m visdom.server -p 8097 &>/dev/null &\n",
      "create web directory ./checkpoints/face_f2_res6_pix2pix/web...\n",
      "/home/Yizhi/anaconda3/envs/pix2pix/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 100, time: 0.345, data: 0.281) G_GAN: 0.738 G_L1: 26.216 D_real: 0.815 D_fake: 0.671 \n",
      "(epoch: 1, iters: 200, time: 0.350, data: 0.002) G_GAN: 0.814 G_L1: 20.006 D_real: 0.634 D_fake: 0.649 \n",
      "(epoch: 1, iters: 300, time: 0.357, data: 0.002) G_GAN: 1.179 G_L1: 21.384 D_real: 0.528 D_fake: 0.429 \n",
      "End of epoch 1 / 20 \t Time Taken: 73 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 80, time: 0.543, data: 0.002) G_GAN: 1.725 G_L1: 21.232 D_real: 0.809 D_fake: 0.134 \n",
      "(epoch: 2, iters: 180, time: 0.355, data: 0.002) G_GAN: 2.542 G_L1: 31.133 D_real: 0.249 D_fake: 0.134 \n",
      "(epoch: 2, iters: 280, time: 0.349, data: 0.002) G_GAN: 2.444 G_L1: 14.873 D_real: 0.313 D_fake: 0.747 \n",
      "End of epoch 2 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 60, time: 0.353, data: 0.002) G_GAN: 1.484 G_L1: 33.341 D_real: 0.577 D_fake: 0.063 \n",
      "(epoch: 3, iters: 160, time: 0.532, data: 0.002) G_GAN: 3.355 G_L1: 20.558 D_real: 0.129 D_fake: 1.206 \n",
      "(epoch: 3, iters: 260, time: 0.355, data: 0.002) G_GAN: 1.033 G_L1: 17.953 D_real: 0.690 D_fake: 0.452 \n",
      "End of epoch 3 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 40, time: 0.349, data: 0.002) G_GAN: 2.033 G_L1: 21.231 D_real: 0.140 D_fake: 0.243 \n",
      "(epoch: 4, iters: 140, time: 0.357, data: 0.002) G_GAN: 1.850 G_L1: 29.728 D_real: 0.228 D_fake: 0.173 \n",
      "(epoch: 4, iters: 240, time: 0.526, data: 0.002) G_GAN: 2.689 G_L1: 25.527 D_real: 0.020 D_fake: 0.127 \n",
      "End of epoch 4 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 20, time: 0.354, data: 0.002) G_GAN: 2.130 G_L1: 21.363 D_real: 0.024 D_fake: 1.181 \n",
      "(epoch: 5, iters: 120, time: 0.358, data: 0.002) G_GAN: 1.837 G_L1: 19.964 D_real: 0.152 D_fake: 0.457 \n",
      "(epoch: 5, iters: 220, time: 0.356, data: 0.002) G_GAN: 2.246 G_L1: 24.513 D_real: 0.018 D_fake: 0.425 \n",
      "(epoch: 5, iters: 320, time: 0.523, data: 0.002) G_GAN: 2.250 G_L1: 24.427 D_real: 0.027 D_fake: 1.134 \n",
      "saving the model at the end of epoch 5, iters 1600\n",
      "End of epoch 5 / 20 \t Time Taken: 68 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.362, data: 0.127) G_GAN: 1.603 G_L1: 21.398 D_real: 0.128 D_fake: 0.520 \n",
      "(epoch: 6, iters: 200, time: 0.355, data: 0.002) G_GAN: 1.086 G_L1: 18.898 D_real: 0.357 D_fake: 0.551 \n",
      "(epoch: 6, iters: 300, time: 0.352, data: 0.002) G_GAN: 2.178 G_L1: 23.768 D_real: 0.513 D_fake: 0.150 \n",
      "End of epoch 6 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 80, time: 0.543, data: 0.002) G_GAN: 1.370 G_L1: 22.840 D_real: 0.096 D_fake: 0.613 \n",
      "(epoch: 7, iters: 180, time: 0.356, data: 0.002) G_GAN: 1.362 G_L1: 17.168 D_real: 0.238 D_fake: 0.355 \n",
      "(epoch: 7, iters: 280, time: 0.353, data: 0.002) G_GAN: 1.722 G_L1: 16.885 D_real: 0.526 D_fake: 0.216 \n",
      "End of epoch 7 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 60, time: 0.348, data: 0.002) G_GAN: 2.514 G_L1: 20.740 D_real: 0.747 D_fake: 0.057 \n",
      "(epoch: 8, iters: 160, time: 0.543, data: 0.002) G_GAN: 2.047 G_L1: 14.645 D_real: 0.125 D_fake: 1.334 \n",
      "(epoch: 8, iters: 260, time: 0.355, data: 0.002) G_GAN: 0.697 G_L1: 13.911 D_real: 0.381 D_fake: 1.464 \n",
      "End of epoch 8 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 40, time: 0.355, data: 0.002) G_GAN: 1.314 G_L1: 26.562 D_real: 0.165 D_fake: 0.323 \n",
      "(epoch: 9, iters: 140, time: 0.349, data: 0.002) G_GAN: 1.670 G_L1: 22.768 D_real: 0.241 D_fake: 0.262 \n",
      "(epoch: 9, iters: 240, time: 0.641, data: 0.002) G_GAN: 1.021 G_L1: 15.478 D_real: 0.355 D_fake: 0.540 \n",
      "End of epoch 9 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 20, time: 0.353, data: 0.002) G_GAN: 0.679 G_L1: 13.411 D_real: 1.083 D_fake: 0.138 \n",
      "(epoch: 10, iters: 120, time: 0.347, data: 0.003) G_GAN: 1.979 G_L1: 16.524 D_real: 0.211 D_fake: 0.412 \n",
      "(epoch: 10, iters: 220, time: 0.353, data: 0.002) G_GAN: 2.468 G_L1: 14.742 D_real: 0.061 D_fake: 1.557 \n",
      "(epoch: 10, iters: 320, time: 0.558, data: 0.002) G_GAN: 1.152 G_L1: 18.647 D_real: 0.266 D_fake: 0.339 \n",
      "saving the model at the end of epoch 10, iters 3200\n",
      "End of epoch 10 / 20 \t Time Taken: 68 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.354, data: 0.112) G_GAN: 1.703 G_L1: 14.031 D_real: 0.255 D_fake: 0.666 \n",
      "(epoch: 11, iters: 200, time: 0.348, data: 0.002) G_GAN: 2.343 G_L1: 18.576 D_real: 0.109 D_fake: 0.778 \n",
      "(epoch: 11, iters: 300, time: 0.361, data: 0.002) G_GAN: 2.072 G_L1: 16.277 D_real: 0.135 D_fake: 0.436 \n",
      "End of epoch 11 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 80, time: 0.550, data: 0.002) G_GAN: 1.940 G_L1: 18.924 D_real: 1.035 D_fake: 0.097 \n",
      "(epoch: 12, iters: 180, time: 0.353, data: 0.002) G_GAN: 1.242 G_L1: 15.820 D_real: 0.549 D_fake: 0.230 \n",
      "(epoch: 12, iters: 280, time: 0.349, data: 0.002) G_GAN: 2.287 G_L1: 22.229 D_real: 0.102 D_fake: 0.241 \n",
      "End of epoch 12 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 60, time: 0.352, data: 0.002) G_GAN: 2.623 G_L1: 18.174 D_real: 0.055 D_fake: 0.130 \n",
      "(epoch: 13, iters: 160, time: 0.589, data: 0.002) G_GAN: 1.663 G_L1: 14.327 D_real: 0.589 D_fake: 0.464 \n",
      "(epoch: 13, iters: 260, time: 0.352, data: 0.002) G_GAN: 0.941 G_L1: 14.706 D_real: 0.105 D_fake: 2.452 \n",
      "End of epoch 13 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 40, time: 0.357, data: 0.002) G_GAN: 2.335 G_L1: 18.307 D_real: 0.082 D_fake: 0.093 \n",
      "(epoch: 14, iters: 140, time: 0.354, data: 0.002) G_GAN: 3.304 G_L1: 14.520 D_real: 0.014 D_fake: 2.032 \n",
      "(epoch: 14, iters: 240, time: 0.566, data: 0.003) G_GAN: 1.252 G_L1: 14.293 D_real: 0.255 D_fake: 0.644 \n",
      "End of epoch 14 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0002000 -> 0.0001667\n",
      "(epoch: 15, iters: 20, time: 0.352, data: 0.002) G_GAN: 2.710 G_L1: 18.389 D_real: 0.154 D_fake: 0.090 \n",
      "(epoch: 15, iters: 120, time: 0.352, data: 0.002) G_GAN: 2.919 G_L1: 15.903 D_real: 0.625 D_fake: 0.056 \n",
      "(epoch: 15, iters: 220, time: 0.352, data: 0.002) G_GAN: 3.715 G_L1: 20.588 D_real: 0.205 D_fake: 0.027 \n",
      "(epoch: 15, iters: 320, time: 0.564, data: 0.002) G_GAN: 1.334 G_L1: 17.155 D_real: 0.253 D_fake: 0.287 \n",
      "saving the model at the end of epoch 15, iters 4800\n",
      "End of epoch 15 / 20 \t Time Taken: 68 sec\n",
      "learning rate 0.0001667 -> 0.0001333\n",
      "(epoch: 16, iters: 100, time: 0.348, data: 0.136) G_GAN: 1.756 G_L1: 10.958 D_real: 0.160 D_fake: 1.099 \n",
      "(epoch: 16, iters: 200, time: 0.350, data: 0.002) G_GAN: 5.576 G_L1: 24.415 D_real: 0.060 D_fake: 0.006 \n",
      "saving the latest model (epoch 16, total_iters 5000)\n",
      "(epoch: 16, iters: 300, time: 0.353, data: 0.002) G_GAN: 3.003 G_L1: 24.764 D_real: 0.135 D_fake: 0.039 \n",
      "End of epoch 16 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0001333 -> 0.0001000\n",
      "(epoch: 17, iters: 80, time: 0.585, data: 0.002) G_GAN: 1.387 G_L1: 9.319 D_real: 0.299 D_fake: 0.589 \n",
      "(epoch: 17, iters: 180, time: 0.354, data: 0.002) G_GAN: 1.930 G_L1: 12.854 D_real: 0.374 D_fake: 0.196 \n",
      "(epoch: 17, iters: 280, time: 0.358, data: 0.002) G_GAN: 1.589 G_L1: 14.544 D_real: 0.488 D_fake: 0.460 \n",
      "End of epoch 17 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0001000 -> 0.0000667\n",
      "(epoch: 18, iters: 60, time: 0.355, data: 0.002) G_GAN: 0.893 G_L1: 9.127 D_real: 0.292 D_fake: 0.918 \n",
      "(epoch: 18, iters: 160, time: 0.618, data: 0.002) G_GAN: 3.872 G_L1: 13.762 D_real: 0.196 D_fake: 0.029 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 260, time: 0.357, data: 0.002) G_GAN: 2.834 G_L1: 15.765 D_real: 0.156 D_fake: 0.083 \n",
      "End of epoch 18 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0000667 -> 0.0000333\n",
      "(epoch: 19, iters: 40, time: 0.356, data: 0.003) G_GAN: 2.447 G_L1: 9.485 D_real: 0.397 D_fake: 0.072 \n",
      "(epoch: 19, iters: 140, time: 0.353, data: 0.002) G_GAN: 0.829 G_L1: 10.677 D_real: 0.150 D_fake: 1.028 \n",
      "(epoch: 19, iters: 240, time: 0.595, data: 0.002) G_GAN: 4.504 G_L1: 14.925 D_real: 0.450 D_fake: 0.011 \n",
      "End of epoch 19 / 20 \t Time Taken: 67 sec\n",
      "learning rate 0.0000333 -> 0.0000000\n",
      "(epoch: 20, iters: 20, time: 0.355, data: 0.002) G_GAN: 7.531 G_L1: 22.873 D_real: 0.153 D_fake: 0.001 \n",
      "(epoch: 20, iters: 120, time: 0.356, data: 0.002) G_GAN: 5.069 G_L1: 19.666 D_real: 0.090 D_fake: 0.008 \n",
      "(epoch: 20, iters: 220, time: 0.358, data: 0.002) G_GAN: 1.064 G_L1: 12.143 D_real: 0.386 D_fake: 0.477 \n",
      "(epoch: 20, iters: 320, time: 0.593, data: 0.002) G_GAN: 0.739 G_L1: 11.296 D_real: 0.134 D_fake: 0.706 \n",
      "saving the model at the end of epoch 20, iters 6400\n",
      "End of epoch 20 / 20 \t Time Taken: 68 sec\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --name face_f2_res6_pix2pix --model pix2pix --netG 'resnet_6blocks' --direction BtoA --n_epochs 15 --n_epochs_decay 5\n",
    "# resnet_6blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facades_label2photo_pretrained\tface_attempt3\t      face_f2_unet128_pix2pix\r\n",
      "facades_pix2pix\t\t\tface_attempt5\t      face_f2_unet256_pix2pix\r\n",
      "face_attemp1_pix2pix\t\tface_attempt_b\t      face_f2unet_pix2pix\r\n",
      "face_attempt1\t\t\tface_f1_pix2pix       horse2zebra\r\n",
      "face_attempt2\t\t\tface_f2_res6_pix2pix  horse2zebra_pretrained\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f2_unet128_pix2pix       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_128                      \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/face_f2_unet128_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 41.829 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/face_f2_unet128_pix2pix/test_latest\n",
      "processing (0000)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00301.jpg']\n",
      "processing (0005)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00306.jpg']\n",
      "processing (0010)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00311.jpg']\n",
      "processing (0015)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00316.jpg']\n",
      "processing (0020)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00321.jpg']\n",
      "processing (0025)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00326.jpg']\n",
      "processing (0030)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00331.jpg']\n",
      "processing (0035)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00336.jpg']\n",
      "processing (0040)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00341.jpg']\n",
      "processing (0045)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00346.jpg']\n",
      "processing (0050)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00421.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --direction BtoA --model pix2pix --netG 'unet_128' --name face_f2_unet128_pix2pix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f2_unet256_pix2pix       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/face_f2_unet256_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/face_f2_unet256_pix2pix/test_latest\n",
      "processing (0000)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00301.jpg']\n",
      "processing (0005)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00306.jpg']\n",
      "processing (0010)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00311.jpg']\n",
      "processing (0015)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00316.jpg']\n",
      "processing (0020)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00321.jpg']\n",
      "processing (0025)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00326.jpg']\n",
      "processing (0030)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00331.jpg']\n",
      "processing (0035)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00336.jpg']\n",
      "processing (0040)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00341.jpg']\n",
      "processing (0045)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00346.jpg']\n",
      "processing (0050)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00421.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --direction BtoA --model pix2pix --netG 'unet_256' --name face_f2_unet256_pix2pix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/real_and_fake_face/scaled_p2p\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \t[default: AtoB]\n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: face_f2_res6_pix2pix          \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_6blocks                \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/face_f2_res6_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 7.841 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/face_f2_res6_pix2pix/test_latest\n",
      "processing (0000)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00301.jpg']\n",
      "processing (0005)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00306.jpg']\n",
      "processing (0010)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00311.jpg']\n",
      "processing (0015)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00316.jpg']\n",
      "processing (0020)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00321.jpg']\n",
      "processing (0025)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00326.jpg']\n",
      "processing (0030)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00331.jpg']\n",
      "processing (0035)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00336.jpg']\n",
      "processing (0040)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00341.jpg']\n",
      "processing (0045)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00346.jpg']\n",
      "processing (0050)-th image... ['./datasets/real_and_fake_face/scaled_p2p/test/real_00421.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/real_and_fake_face/scaled_p2p --direction BtoA --model pix2pix --netG 'resnet_6blocks' --name face_f2_res6_pix2pix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
